1. First let’s make sure you understand how the programs generally work, and
some of the key options. Study the code in vector-deadlock.c, as well
as in main-common.c and related files.
Now, run ./vector-deadlock -n 2 -l 1 -v, which instantiates two
threads (-n 2), each of which does one vector add (-l 1), and does so in
verbose mode (-v). Make sure you understand the output. How does the
output change from run to run?


A: output stays the same except its order which Thread runs first does change tho


2. Now add the -d flag, and change the number of loops (-l) from 1 to higher
numbers. What happens? Does the code (always) deadlock?


A: deadlocks rarity decreases rapitly over 100000 loops


3. How does changing the number of threads (-n) change the outcome of the
program? Are there any values of -n that ensure no deadlock occurs?

A: no deadlock at -n 1, but else everywhere


4. Now examine the code in vector-global-order.c. First, make sure you
understand what the code is trying to do; do you understand why the code
avoids deadlock? Also, why is there a special case in this vector add()
routine when the source and destination vectors are the same?

A: this add function holds the less values lock out of both first, and if equal it needs to hold one lock. therefore there is no deadlock here.... 


5. Now run the code with the following flags: -t -n 2 -l 100000 -d.
How long does the code take to complete? How does the total time change
when you increase the number of loops, or the number of threads?

A: it takes: Time: 0.10 seconds
with increased loop to 1000000: Time: 1.10 seconds
		       10000000: Time: 7.56 seconds
		       100000000: took too long ....

with increased threadNumber to 10: 	Time: 0.32 seconds
		       20:	 	Time: 0.55 seconds
		       30: 		Time: 0.82 seconds
		       50: 		Time: 1.02 seconds
		       75: 		Time: 1.69 seconds

with increased threadNumber to 99 and loop 10000000: Time: 21.00 seconds

A: the Time increases almost propotional

6. What happens if you turn on the parallelism flag (-p)? How much would
you expect performance to change when each thread is working on adding
different vectors (which is what -p enables) versus working on the same
ones?

A: 
with increased threadNumber to 99 and loop 10000000: 
-> Time: 21.00 seconds

with -p -> Time: 9.06 seconds

thus its twice as fast as without parallism. its even faster with increased threads ! 

ps: 
with 10000000 -d -p
Time: 93.74 seconds
cpu performance is at 50% xD 
without -p its at 34% and takkkkkkeeeesss toooooo lonnnnggg TIME: 216.26 seconds



7. Now let’s study vector-try-wait.c. First make sure you understand
the code. Is the first call to pthread mutex trylock() really needed?
Now run the code. How fast does it run compared to the global order approach? How does the number of retries, as counted by the code, change as
the number of threads increases?

A: Der erste trylock-Aufruf ist notwendig, ohne den kann das Programm nicht den Lock haben.
Die Laufzeit ohne -p ist sehr variant, mal schneller als global oder mal langsamer, hängt von der Anzahl der Retries ab.
Die Laufzeit mit -p ist gleich wie globalorder oder schneller.
Mit -p ist Retries immer 0 wenn die Anzahl der Threads aufsteigt.
Ohne -p:
            Anzahl Threads                  Retries
                2                           122707
                3                           1264127
                4                           2407310
                5                           2831307
                6                           4345401
                7                           5652965


8. Now let’s look at vector-avoid-hold-and-wait.c. What is the main
problem with this approach? How does its performance compare to the
other versions, when running both with -p and without it?

A: its slower with or without -p tho with -p its even worse. thus it doesn't scale very well with concurrency, as it has a global lock and a fixed order.




9. Finally, let’s look at vector-nolock.c. This version doesn’t use locks at
all; does it provide the exact same semantics as the other versions? Why or
why not?

A: it does well 'cause calculations are atomic on the Harware level therefore theres no deadlock to be seen here. 




10. Now compare its performance to the other versions, both when threads are
working on the same two vectors (no -p) and when each thread is working
on separate vectors (-p). How does this no-lock version perform?
A: without -p 
-> Its slower than global order cause it doesnt scale well with increasing Threads, but its better than hold_and_wait and Try_wait.
Mit -p:
Ähnlich wie ohne p.
unterschied: Mit gleicher Loops und groß genug Anzahl von Threads ist no_nock nur schneller als avoid_hold_and_wait.